{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef2feffb-00d3-4324-affd-a6831af4c514",
   "metadata": {},
   "source": [
    "# Country_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ddf25-7cdf-4827-9496-16ff3716477f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989fd0d-b57c-4c5a-a72d-635a21805e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "# Change the driver path to your computer\n",
    "driver_path = r'C:\\Users\\panda\\Downloads\\chromedriver_win32\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(driver_path)\n",
    "#Open the website\n",
    "driver.get(\"https://climexp.knmi.nl/plot_atlas_form.py\")\n",
    "#1. Select \"countries\"\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[2]/td[2]/input[7]\").click()\n",
    "#2. Select \"time series\"\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div/div[1]/div[2]/div/form/table/tbody/tr[10]/td[2]/input[3]\").click()\n",
    "#3. Check RCPs\n",
    "#rcp2.6\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[12]/td[2]/input[1]\").click()\n",
    "#rcp4.5 has been clicked by default\n",
    "#rcp6.0\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[12]/td[2]/input[3]\").click()\n",
    "#rcp8.5\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[12]/td[2]/input[4]\").click()\n",
    "\n",
    "#4. input years for each country\n",
    "## Clear values first\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div/div[1]/div[2]/div/form/table/tbody/tr[13]/td[2]/input[1]\").clear()\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[13]/td[2]/input[2]\").clear()\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div/div[1]/div[2]/div/form/table/tbody/tr[13]/td[2]/input[1]\").send_keys(2005)\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[13]/td[2]/input[2]\").send_keys(2005)\n",
    "\n",
    "#4.5 Get rid of some useless countries\n",
    "optionsList = pd.read_excel('optionsList.xlsx')\n",
    "optionsList = list(optionsList['Country'])\n",
    "\n",
    "#5. Looping the countries\n",
    "for optionValue in optionsList:\n",
    "    print (f\"starting loop on option: {optionValue}\")\n",
    "    select = Select(driver.find_element(by=By.XPATH, value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[3]/td[2]/select\"))\n",
    "    select.select_by_value(optionValue)\n",
    "\n",
    "    #6. Click \"Make time series\"\n",
    "    driver.find_element(by=By.XPATH, \n",
    "                        value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[16]/td/input\").click()\n",
    "        \n",
    "    #This step will take 15 minutes to 1 hour to extracte data files\n",
    "    #since they used some kind of .py file.\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\"))\n",
    "        )\n",
    "    except:\n",
    "        element = WebDriverWait(driver, 3600).until(\n",
    "            EC.presence_of_element_located((by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\"))\n",
    "        )\n",
    "        \n",
    "    #7. Get all data\n",
    "    driver.find_element(by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\").click()\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\"))\n",
    "        )\n",
    "    except:\n",
    "        element = WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\"))\n",
    "        )\n",
    "    #8. Download data\n",
    "    driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div/div[1]/p/a\").click()\n",
    "    if optionValue == 'Zimbabwe':\n",
    "        driver.quit()\n",
    "    else:\n",
    "        driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5beb6-0a56-4eee-88ba-62e8ec6bd5a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Second Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fed09-7091-4cf8-9759-c81f6ff11758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "## Get all zipped file names\n",
    "filelist = []\n",
    "# Please confirm the download location\n",
    "path = \"C:/Users/panda/Downloads/Country/\"\n",
    "for file in os.listdir(f\"{path}\"):\n",
    "    if file.endswith(\".zip\"):\n",
    "        filelist.append(file)\n",
    "## First loop for extracting all files\n",
    "for i in range(len(filelist)):\n",
    "    filepath = path + filelist[i]\n",
    "    unzip=zipfile.ZipFile(filepath)\n",
    "    unzip.extractall(f'{path}')\n",
    "    unzip.close()\n",
    "    rcppath = path + 'atlas/series/CMIP5one'\n",
    "    # list rcp folders \n",
    "    rcp = [dI for dI in os.listdir(f'{rcppath}') if os.path.isdir(os.path.join(f'{rcppath}',dI))]\n",
    "    ### First.1 loop for getting rcp folders path & get all countries for each rcp\n",
    "    for j in rcp[1:]:\n",
    "        RCP = rcppath + '/' + j \n",
    "        monthly = [dI for dI in os.listdir(f'{RCP}') if os.path.isdir(os.path.join(f'{RCP}',dI))]\n",
    "        # 1850-2005\n",
    "        MON1 = RCP + '/' + monthly[0]\n",
    "        country = [dI for dI in os.listdir(f'{MON1}') if os.path.isdir(os.path.join(f'{MON1}',dI))]\n",
    "## Second loop for read rcp files then get the paths of hist (1850 - 2005) and future data (2006 - 2100)\n",
    "for j in rcp[1:]:\n",
    "    RCP = rcppath + '/' + j \n",
    "    monthly = [dI for dI in os.listdir(f'{RCP}') if os.path.isdir(os.path.join(f'{RCP}',dI))]\n",
    "    # 1850-2005\n",
    "    MON1 = RCP + '/' + monthly[0]\n",
    "    # 2006-2100\n",
    "    MON2 = RCP + '/' + monthly[1]\n",
    "    ### Second.1 loop to get all hist and future data\n",
    "    for q in range(len(country)):\n",
    "        # 1850-2005\n",
    "        CON1 = MON1 + '/' + country[q]\n",
    "        txtlist1 = []\n",
    "        for txt1 in os.listdir(f\"{CON1}\"):\n",
    "            if txt1.endswith(\".txt\"):\n",
    "                txtlist1.append(txt1)\n",
    "        # 2006-2100\n",
    "        CON2 = MON2 + '/' + country[q]\n",
    "        txtlist2 = []\n",
    "        for txt2 in os.listdir(f\"{CON2}\"):\n",
    "            if txt2.endswith(\".txt\"):\n",
    "                txtlist2.append(txt2)\n",
    "                \n",
    "                \n",
    "        #### Second.1.1 loop to read all hist data and caculate the mean\n",
    "        for k in range(len(txtlist1)):\n",
    "            if k == 0:\n",
    "                txtfile = CON1 + '/' + txtlist1[k]\n",
    "                df = pd.read_csv(f\"{txtfile}\", on_bad_lines='skip')\n",
    "                try: # some txt file doesnot contain data.\n",
    "                    df = df[-156:]\n",
    "                    df.rename(columns= {df.columns[0]:f'Model{k}'}, inplace = True)\n",
    "                    df = df[f'Model{k}'].str.rsplit(\"       \",expand=True)\n",
    "                    df = df[1].str.rsplit(\"     \", expand=True)\n",
    "                    df = df[1].str.rsplit(\"   \", expand=True).add_prefix('nCol_').join(df)\n",
    "                    df = df[[0,'nCol_0']]\n",
    "                    df.rename(columns={0: f'Model{k}', 'nCol_0': 'Year'}, inplace=True)\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                txtfile = CON1 + '/' + txtlist1[k]\n",
    "                dt = pd.read_csv(f\"{txtfile}\", on_bad_lines='skip')\n",
    "                try: # some txt file doesnot contain data.\n",
    "                    dt = dt[-156:]\n",
    "                    dt.rename(columns= {dt.columns[0]:f'Model{k}'}, inplace = True)\n",
    "                    dt = dt[f'Model{k}'].str.rsplit(\"       \",expand=True)\n",
    "                    dt = dt[1].str.rsplit(\"     \", expand=True)\n",
    "                    dt = dt[1].str.rsplit(\"   \", expand=True).add_prefix('nCol_').join(dt)\n",
    "                    dt = dt[[0,'nCol_0']]\n",
    "                    dt.rename(columns={0: f'Model{k}', 'nCol_0': 'Year'}, inplace=True)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                df = df.merge(dt, on = 'Year', how = 'left')\n",
    "\n",
    "        df = df.astype(float)\n",
    "        df = df.set_index('Year')\n",
    "        df['mean'] = df.mean(axis=1)\n",
    "        country1 = [country[q]]*len(df)\n",
    "        df['Country'] = country1\n",
    "        df = df[['mean','Country']]\n",
    "        df.rename(columns= {'mean':f'{j}'},inplace = True)\n",
    "        dfhist = df \n",
    "        \n",
    "        #### Second.1.2 loop to read all future data and caculate the mean\n",
    "        df  = pd.DataFrame()\n",
    "        for k in range(len(txtlist2)):\n",
    "            if k == 0:\n",
    "                txtfile = CON2 + '/' + txtlist2[k]\n",
    "                df = pd.read_csv(f\"{txtfile}\", on_bad_lines='skip')\n",
    "                try: # some txt file doesnot contain data.\n",
    "                    df = df[-95:]\n",
    "                    df.rename(columns= {df.columns[0]:f'Model{k}'}, inplace = True)\n",
    "                    df = df[f'Model{k}'].str.rsplit(\"       \",expand=True)\n",
    "                    df = df[1].str.rsplit(\"     \", expand=True)\n",
    "                    df = df[1].str.rsplit(\"   \", expand=True).add_prefix('nCol_').join(df)\n",
    "                    df = df[[0,'nCol_0']]\n",
    "                    df.rename(columns={0: f'Model{k}', 'nCol_0': 'Year'}, inplace=True)\n",
    "                except:\n",
    "                    continue\n",
    "                    \n",
    "            else:\n",
    "                txtfile = CON2 + '/' + txtlist2[k]\n",
    "                dt = pd.read_csv(f\"{txtfile}\", on_bad_lines='skip')\n",
    "                try: # some txt file doesnot contain data.\n",
    "                    dt = dt[-95:]\n",
    "                    dt.rename(columns= {dt.columns[0]:f'Model{k}'}, inplace = True)\n",
    "                    dt = dt[f'Model{k}'].str.rsplit(\"       \",expand=True)\n",
    "                    dt = dt[1].str.rsplit(\"     \", expand=True)\n",
    "                    dt = dt[1].str.rsplit(\"   \", expand=True).add_prefix('nCol_').join(dt)\n",
    "                    dt = dt[[0,'nCol_0']]\n",
    "                    dt.rename(columns={0: f'Model{k}', 'nCol_0': 'Year'}, inplace=True)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                df = df.merge(dt, on = 'Year', how = 'left')\n",
    "\n",
    "        df = df.astype(float)\n",
    "        df = df.set_index('Year')\n",
    "        df['mean'] = df.mean(axis=1)\n",
    "        country2 = [country[q]]*len(df)\n",
    "        df['Country'] = country2\n",
    "        df = df[['mean','Country']]\n",
    "        df.rename(columns= {'mean':f'{j}'},inplace = True)\n",
    "        dffuture = df\n",
    "\n",
    "        ## Combine hist and future\n",
    "        # Create new folders under current directory: country/rcp26,rcp45,rcp60,rcp85\n",
    "        dd = pd.concat([dfhist, dffuture])\n",
    "        dd.to_excel(f'country/{j}/{country[q]}{j}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898964b-2c9c-4c0b-b586-491b33f3ece6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Third Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf2faf-3521-466a-bc09-594b3952db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dire = 'C:/Users/panda/OneDrive - University of Denver/Pardee Center/17 2022 Summer/country'\n",
    "# dire needs to change\n",
    "subfolders = [ f.path for f in os.scandir(f\"{dire}\") if f.is_dir() ]\n",
    "for p in subfolders:\n",
    "    excellist = []\n",
    "    for excel in os.listdir(f\"{p}\"):\n",
    "        if excel.endswith(\".xlsx\"):\n",
    "            excellist.append(excel)\n",
    "        for a in range(len(excellist)):\n",
    "            value = excellist[a][:-5]\n",
    "            value = value[-5:]\n",
    "            if a == 0:\n",
    "                df = pd.read_excel(f'{p}/{excellist[a]}')\n",
    "            else:\n",
    "                dt = pd.read_excel(f'{p}/{excellist[a]}')\n",
    "\n",
    "            final = pd.concat([df,dt])\n",
    "            final = final.pivot_table(index = 'Country', columns = 'Year', values = f'{value}')\n",
    "        \n",
    "        final.to_excel(f\"{p}/{value}_countrylevel.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba1dc03-757e-4b18-b2d2-cc56a6db46c1",
   "metadata": {},
   "source": [
    "# Region_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cbb52e-3f25-4240-8607-ea463fad387b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86724858-5189-4c5f-adc9-9001282adf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "# Change the driver path to your computer\n",
    "driver_path = r'C:\\Users\\panda\\Downloads\\chromedriver_win32\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(driver_path)\n",
    "#Open the website\n",
    "driver.get(\"https://climexp.knmi.nl/plot_atlas_form.py\")\n",
    "#1. Select \"time series\"\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div/div[1]/div[2]/div/form/table/tbody/tr[10]/td[2]/input[3]\").click()\n",
    "#2. Check RCPs\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[12]/td[2]/input[1]\").click()\n",
    "#rcp4.5 has been clicked by default\n",
    "#driver.find_element(by=By.XPATH, \n",
    "                    #value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[12]/td[2]/input[2]\").click()\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[12]/td[2]/input[3]\").click()\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[12]/td[2]/input[4]\").click()\n",
    "#3. input years for each region\n",
    "## Clear values first\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div/div[1]/div[2]/div/form/table/tbody/tr[13]/td[2]/input[1]\").clear()\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[13]/td[2]/input[2]\").clear()\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div/div[1]/div[2]/div/form/table/tbody/tr[13]/td[2]/input[1]\").send_keys(2005)\n",
    "driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[13]/td[2]/input[2]\").send_keys(2005)\n",
    "\n",
    "# Get the full list of regions\n",
    "select = driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[3]/td[2]/select\")  #get the select element            \n",
    "options = select.find_elements(by=By.TAG_NAME, value=\"option\") #get all the options into a list\n",
    "\n",
    "optionsList = []\n",
    "\n",
    "for option in options: #iterate over the options, place attribute value in list\n",
    "    optionsList.append(option.get_attribute(\"value\"))\n",
    "    \n",
    "#4. Looping the regions\n",
    "for optionValue in optionsList:\n",
    "    print (f\"starting loop on option: {optionValue}\")\n",
    "    select = Select(driver.find_element(by=By.XPATH, value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[3]/td[2]/select\"))\n",
    "    select.select_by_value(optionValue)\n",
    "    \n",
    "    #5. Click \"Make time series\"\n",
    "    driver.find_element(by=By.XPATH, \n",
    "                        value = \"/html/body/div[3]/div[1]/div[1]/div[2]/div/form/table/tbody/tr[16]/td/input\").click()\n",
    "        \n",
    "    #This step will take 15 minutes to 1 hour to extracte data files\n",
    "    #since they used some kind of .py file.\n",
    "    \n",
    "    try:\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\"))\n",
    "        )\n",
    "    except:\n",
    "        element = WebDriverWait(driver, 3600).until(\n",
    "            EC.presence_of_element_located((by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\"))\n",
    "        )\n",
    "        \n",
    "    #6. Get all data\n",
    "    driver.find_element(by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\").click()\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\"))\n",
    "        )\n",
    "    except:\n",
    "        element = WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((by=By.XPATH, \n",
    "                value = \"/html/body/div[3]/div[2]/a[5]\"))\n",
    "        )\n",
    "    #7. Download data\n",
    "    driver.find_element(by=By.XPATH, \n",
    "                    value = \"/html/body/div[3]/div/div[1]/p/a\").click()\n",
    "    if optionValue == 'Antarcticsea':\n",
    "        driver.quit()\n",
    "    else:\n",
    "        driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d74cf-e2b5-481e-8bf0-28c56985a90c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Second Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c66adc4-e1fb-428b-9be2-5393fec5be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "filelist = []\n",
    "# Please confirm the download location\n",
    "path = \"C:/Users/panda/Downloads/Region/\"\n",
    "## Get all zipped file names\n",
    "for file in os.listdir(f\"{path}\"):\n",
    "    if file.endswith(\".zip\"):\n",
    "        filelist.append(file)\n",
    "## First loop for extracting all files\n",
    "for i in range(len(filelist)):\n",
    "    filepath = path + filelist[i]\n",
    "    unzip=zipfile.ZipFile(filepath)\n",
    "    unzip.extractall(f'{path}')\n",
    "    unzip.close()\n",
    "    rcppath = path + 'atlas/series/CMIP5one'\n",
    "    ### First.1 loop for getting rcp folders path\n",
    "    # list rcp folders \n",
    "    rcp = [dI for dI in os.listdir(f'{rcppath}') if os.path.isdir(os.path.join(f'{rcppath}',dI))]\n",
    "    #get all regions for each rcp\n",
    "    for j in rcp[1:]:\n",
    "        RCP = rcppath + '/' + j \n",
    "        monthly = [dI for dI in os.listdir(f'{RCP}') if os.path.isdir(os.path.join(f'{RCP}',dI))]\n",
    "        # 1850-2005\n",
    "        MON1 = RCP + '/' + monthly[0]\n",
    "        region = [dI for dI in os.listdir(f'{MON1}') if os.path.isdir(os.path.join(f'{MON1}',dI))]\n",
    "## Second loop for read rcp files then get the paths of hist (1850 - 2005) and future data (2006 - 2100)\n",
    "for j in rcp[1:]:\n",
    "    RCP = rcppath + '/' + j \n",
    "    monthly = [dI for dI in os.listdir(f'{RCP}') if os.path.isdir(os.path.join(f'{RCP}',dI))]\n",
    "    # 1850-2005\n",
    "    MON1 = RCP + '/' + monthly[0]\n",
    "    # 2006-2100\n",
    "    MON2 = RCP + '/' + monthly[1]\n",
    "    ### Second.1 loop to get all hist and future data\n",
    "    for q in range(len(region)):\n",
    "        # 1850-2005\n",
    "        CON1 = MON1 + '/' + region[q]\n",
    "        txtlist1 = []\n",
    "        for txt1 in os.listdir(f\"{CON1}\"):\n",
    "            if txt1.endswith(\".txt\"):\n",
    "                txtlist1.append(txt1)\n",
    "        # 2006-2100\n",
    "        CON2 = MON2 + '/' + region[q]\n",
    "        txtlist2 = []\n",
    "        for txt2 in os.listdir(f\"{CON2}\"):\n",
    "            if txt2.endswith(\".txt\"):\n",
    "                txtlist2.append(txt2)      \n",
    "                \n",
    "                \n",
    "        #### Second.1.1 loop to read all hist data and caculate the mean\n",
    "        for k in range(len(txtlist1)):\n",
    "            if k == 0:\n",
    "                txtfile = CON1 + '/' + txtlist1[k]\n",
    "                #print(\"hist\",region[q],txtlist1[k])\n",
    "                df = pd.read_csv(f\"{txtfile}\", on_bad_lines='skip')\n",
    "                try: # some txt file doesnot contain data.\n",
    "                    df = df[-156:]\n",
    "                    df.rename(columns= {df.columns[0]:f'Model{k}'}, inplace = True)\n",
    "                    df = df[f'Model{k}'].str.rsplit(\"       \",expand=True)\n",
    "                    df = df[1].str.rsplit(\"     \", expand=True)\n",
    "                    df = df[1].str.rsplit(\"   \", expand=True).add_prefix('nCol_').join(df)\n",
    "                    df = df[[0,'nCol_0']]\n",
    "                    df.rename(columns={0: f'Model{k}', 'nCol_0': 'Year'}, inplace=True)\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                txtfile = CON1 + '/' + txtlist1[k]\n",
    "                #print(\"hist\",region[q],txtlist1[k])\n",
    "                dt = pd.read_csv(f\"{txtfile}\", on_bad_lines='skip')\n",
    "                try: # some txt file doesnot contain data.\n",
    "                    dt = dt[-156:]\n",
    "                    dt.rename(columns= {dt.columns[0]:f'Model{k}'}, inplace = True)\n",
    "                    dt = dt[f'Model{k}'].str.rsplit(\"       \",expand=True)\n",
    "                    dt = dt[1].str.rsplit(\"     \", expand=True)\n",
    "                    dt = dt[1].str.rsplit(\"   \", expand=True).add_prefix('nCol_').join(dt)\n",
    "                    dt = dt[[0,'nCol_0']]\n",
    "                    dt.rename(columns={0: f'Model{k}', 'nCol_0': 'Year'}, inplace=True)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                df = df.merge(dt, on = 'Year', how = 'left')\n",
    "\n",
    "        df = df.astype(float)\n",
    "        df = df.set_index('Year')\n",
    "        df['mean'] = df.mean(axis=1)\n",
    "        region1 = [region[q]]*len(df)\n",
    "        df['Country'] = region1\n",
    "        df = df[['mean','Country']]\n",
    "        df.rename(columns= {'mean':f'{j}'},inplace = True)\n",
    "        dfhist = df \n",
    "        \n",
    "        #### Second.1.2 loop to read all future data and caculate the mean\n",
    "        df  = pd.DataFrame()\n",
    "        for k in range(len(txtlist2)):\n",
    "            if k == 0:\n",
    "                txtfile = CON2 + '/' + txtlist2[k]\n",
    "                #print(\"future\",region[q],txtlist2[k])\n",
    "                df = pd.read_csv(f\"{txtfile}\", on_bad_lines='skip')\n",
    "                try: # some txt file doesnot contain data.\n",
    "                    df = df[-95:]\n",
    "                    df.rename(columns= {df.columns[0]:f'Model{k}'}, inplace = True)\n",
    "                    df = df[f'Model{k}'].str.rsplit(\"       \",expand=True)\n",
    "                    df = df[1].str.rsplit(\"     \", expand=True)\n",
    "                    df = df[1].str.rsplit(\"   \", expand=True).add_prefix('nCol_').join(df)\n",
    "                    df = df[[0,'nCol_0']]\n",
    "                    df.rename(columns={0: f'Model{k}', 'nCol_0': 'Year'}, inplace=True)\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                txtfile = CON2 + '/' + txtlist2[k]\n",
    "                #print(\"future\",region[q],txtlist2[k])\n",
    "                dt = pd.read_csv(f\"{txtfile}\", on_bad_lines='skip')\n",
    "                try: # some txt file doesnot contain data.\n",
    "                    dt = dt[-95:]\n",
    "                    dt.rename(columns= {dt.columns[0]:f'Model{k}'}, inplace = True)\n",
    "                    dt = dt[f'Model{k}'].str.rsplit(\"       \",expand=True)\n",
    "                    dt = dt[1].str.rsplit(\"     \", expand=True)\n",
    "                    dt = dt[1].str.rsplit(\"   \", expand=True).add_prefix('nCol_').join(dt)\n",
    "                    dt = dt[[0,'nCol_0']]\n",
    "                    dt.rename(columns={0: f'Model{k}', 'nCol_0': 'Year'}, inplace=True)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                df = df.merge(dt, on = 'Year', how = 'left')\n",
    "\n",
    "        df = df.astype(float)\n",
    "        df = df.set_index('Year')\n",
    "        df['mean'] = df.mean(axis=1)\n",
    "        region2 = [region[q]]*len(df)\n",
    "        df['Country'] = region2\n",
    "        df = df[['mean','Country']]\n",
    "        df.rename(columns= {'mean':f'{j}'},inplace = True)\n",
    "        dffuture = df\n",
    "        \n",
    "        ## Combine hist and future\n",
    "        # Create new folders under current directory: region/rcp26,rcp45,rcp60,rcp85\n",
    "        dd = pd.concat([dfhist, dffuture])\n",
    "        dd.to_excel(f'region/{j}/{region[q]}{j}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d68c26cf-a72a-482c-963e-7f50b08bbf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># correlate time_tas_Amon_GFDL-ESM2G_rcp45_r1i1p1_world.dat time mon 1 ave 12 begin 2006 standardunits dump time_tas_Amon_GFDL-ESM2G_rcp45_r1i1p1_world_mon1_ave12_dump1.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># tas [Celsius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># file :: atlas/series/CMIP5/rcp45/monthly/wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># olderfile :: CMIP5/monthly/tas/tas_Amon_GFDL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># cdi :: Climate Data Interface version 1.5.9 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># parent_experiment_rip :: r1i1p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td># cdo :: Climate Data Operators version 1.5.9 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td># institute_id :: NOAA GFDL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td># contact :: gfdl.climate.model.info@noaa.gov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td># project_id :: CMIP5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td># table_id :: Table Amon (31 Jan 2011)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td># experiment_id :: historical+rcp45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td># realization ::        1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td># modeling_realm :: atmos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td># tracking_id :: a255b783-f23b-44a6-ab42-a4178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td># gfdl_experiment_name :: ESM2G-HC2_2006-2100_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td># creation_date :: 2011-11-21T19:54:22Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td># model_id :: GFDL-ESM2G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td># branch_time :: 52925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td># experiment :: RCP4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td># frequency :: mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td># initialization_method ::        1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td># parent_experiment_id :: historical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td># physics_version ::        1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td># product :: output1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # correlate time_tas_Amon_GFDL-ESM2G_rcp45_r1i1p1_world.dat time mon 1 ave 12 begin 2006 standardunits dump time_tas_Amon_GFDL-ESM2G_rcp45_r1i1p1_world_mon1_ave12_dump1.txt\n",
       "0                                     # tas [Celsius]                                                                                                                          \n",
       "1   # file :: atlas/series/CMIP5/rcp45/monthly/wor...                                                                                                                          \n",
       "2   # olderfile :: CMIP5/monthly/tas/tas_Amon_GFDL...                                                                                                                          \n",
       "3   # cdi :: Climate Data Interface version 1.5.9 ...                                                                                                                          \n",
       "4                   # parent_experiment_rip :: r1i1p1                                                                                                                          \n",
       "5   # cdo :: Climate Data Operators version 1.5.9 ...                                                                                                                          \n",
       "6                         # institute_id :: NOAA GFDL                                                                                                                          \n",
       "7       # contact :: gfdl.climate.model.info@noaa.gov                                                                                                                          \n",
       "8                               # project_id :: CMIP5                                                                                                                          \n",
       "9              # table_id :: Table Amon (31 Jan 2011)                                                                                                                          \n",
       "10                # experiment_id :: historical+rcp45                                                                                                                          \n",
       "11                          # realization ::        1                                                                                                                          \n",
       "12                          # modeling_realm :: atmos                                                                                                                          \n",
       "13  # tracking_id :: a255b783-f23b-44a6-ab42-a4178...                                                                                                                          \n",
       "14  # gfdl_experiment_name :: ESM2G-HC2_2006-2100_...                                                                                                                          \n",
       "15            # creation_date :: 2011-11-21T19:54:22Z                                                                                                                          \n",
       "16                           # model_id :: GFDL-ESM2G                                                                                                                          \n",
       "17                             # branch_time :: 52925                                                                                                                          \n",
       "18                             # experiment :: RCP4.5                                                                                                                          \n",
       "19                                 # frequency :: mon                                                                                                                          \n",
       "20                # initialization_method ::        1                                                                                                                          \n",
       "21               # parent_experiment_id :: historical                                                                                                                          \n",
       "22                      # physics_version ::        1                                                                                                                          \n",
       "23                               # product :: output1                                                                                                                          "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The txt file does not contain data.\n",
    "item = pd.read_csv('C:/Users/panda/Downloads/Region/atlas/series/CMIP5one/rcp45/monthly_dump1/world/time_tas_Amon_GFDL-ESM2G_rcp45_r1i1p1_world_mon1_ave12_dump1.txt', on_bad_lines='skip')\n",
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57478c61-5fb1-4e68-a27f-af4399c822b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Third Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b750ea51-2967-46de-9a0b-fe12fcc05fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dire = 'C:/Users/panda/OneDrive - University of Denver/Pardee Center/17 2022 Summer/region'\n",
    "# dire needs to change\n",
    "subfolders = [ f.path for f in os.scandir(f\"{dire}\") if f.is_dir() ]\n",
    "for p in subfolders:\n",
    "    excellist = []\n",
    "    for excel in os.listdir(f\"{p}\"):\n",
    "        if excel.endswith(\".xlsx\"):\n",
    "            excellist.append(excel)\n",
    "        for a in range(len(excellist)):\n",
    "            value = excellist[a][:-5]\n",
    "            value = value[-5:]\n",
    "            if a == 0:\n",
    "                df = pd.read_excel(f'{p}/{excellist[a]}')\n",
    "            else:\n",
    "                dt = pd.read_excel(f'{p}/{excellist[a]}')\n",
    "\n",
    "            final = pd.concat([df,dt])\n",
    "            final = final.pivot_table(index = 'Country', columns = 'Year', values = f'{value}')\n",
    "        \n",
    "        final.to_excel(f\"{p}/{value}_regionlevel.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
